'''
Code to align the coordinates from neuropixels data to different areas in mouse brains. 

We will take a series of landmarks in probe space (microns from first channel, as generated
in main_probe_location.py) and in brainreg space (microns from the tip of a specific track, as 
generated by brainreg-segmentation). 

Using this, we will align each shank with an area in the Allen Brain Atlas, and will give the Allen Brain coordinates of
each point. 

When we have one landmark, we can only align the two tracks and assume that the warping generated by registering the brain
is not relevant. With two landmarks, we linearly approximate the warping. 

WE ASSUME THAT THE PROBE_LOCATION MAPPING IS IN MICRONS FROM ELECTRODE 0, WHEREAS THE BRAINREG MAPPING
IS IN MICRONS FROM THE POINT CLOSEST TO THE SURFACE. THIS IS VERY IMPORTANT. 
'''

import pandas as pd
import numpy as np
from pathlib import Path
import json
import logging

BRAINREG_INPUT = '/Volumes/sjones/projects/FlexiVexi/brainreg'
NPX_INPUT = '/Volumes/sjones/projects/FlexiVexi/data_analysis/probe_location'



class ProbeAligner:

    def __init__(self, mouse, feature_dict, n_shanks=4, harmonize_n_features = True):
        """
        Initializes the ProbeAligner with mouse data, feature configurations, and input paths.

        Parameters:
        - mouse (str): Identifier for the mouse.
        - feature_dict (dict): Dictionary containing features for each shank.
        - brainreg_input (str): Base path for brainreg input data.
        - npx_input (str): Base path for NPX input data.
        - n_shanks (int): Number of shanks to process. Default is 4.
        - harmonize_n_features (bool): Wether to use a linear adjustment for all shanks
        when more than one feature is only present for some shanks. It calculates
        the average slope and uses it. 
        """
        self.mouse = mouse
        self.feature_dict = feature_dict
        self.n_shanks = n_shanks
        self.harmonize = harmonize_n_features

        # Define and initialize paths as properties
        self.brainreg_path = Path(BRAINREG_INPUT) / mouse / 'segmentation' / 'atlas_space' / 'tracks'
        self.npx_path = Path(NPX_INPUT) / mouse / 'whole_probe_four_shanks'
        self.output_path = Path(NPX_INPUT) / mouse / 'Allen_Brain'

        # Create the output directory if it doesn't exist
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # Optional: Initialize data storage for merged DataFrames
        self.merged_data = {}
        self.mappings = {}

    def align_shanks(self):

        self.determine_approximation_mode()

        if (self.approximation_mode == 'linear') or (self.approximation_mode == 'align') or (self.approximation_mode == 'mixed'):

            for shank in np.arange(self.n_shanks):
                self.align_single_shank(int(shank))

        elif self.approximation_mode == 'harmonize':
            self.linear_list = []
            self.harmonized_list =  []

            for i in np.arange(self.n_shanks):
                if self.features_lengths[i]>1:
                    self.linear_list.append(i)
                else:
                    self.harmonized_list.append(i)
            
            for shank in self.linear_list:
                self.align_single_shank(int(shank))

            for shank in self.harmonized_list:
                self.align_single_shank(int(shank), harmonised = True)
            
            
        self.params = {
            'mouse': self.mouse,
            'approximation_mode': self.approximation_mode, 
            'feature_dict': self.feature_dict, 
            'mapping': self.mappings
            }
        
        # Save params as JSON in the same path
        json_file_path = self.output_path / f'params.json'
        with open(json_file_path, 'w') as json_file:
            json.dump(self.params, json_file, indent=4)
        print(f"Params saved to {json_file_path}")

    def align_single_shank(self, shank, harmonised = False):

        #PReparing data

        print(f'LOOKING AT SHANK {shank}')
        self.mappings[shank] = {}

        features = self.feature_dict[f'shank_{shank}']

        features_brainreg = features['features_brainreg']
        features_npx = features['features_npx']


        brainreg_shank = pd.read_csv(self.brainreg_path / f'track_{shank}.csv')
        allen_coordinates = np.load(self.brainreg_path / f'track_{shank}.npy')
        brainreg_shank['allen_x'] = allen_coordinates[:,0]
        brainreg_shank['allen_y'] = allen_coordinates[:,1]
        brainreg_shank['allen_z'] = allen_coordinates[:, 2]

        npx_all = pd.read_csv(self.npx_path / 'complete_probemap.csv')
        shank_filter = npx_all['contact_ids'].str.startswith(f's{shank}')
        npx_shank = npx_all[shank_filter]

        #Reversing the direction: from the surface to the bottom, and not otherwise
        #THIS IS THE STEP THAT REVERSES THE DIRECTION, PLEASE BE CAREFUL
        npx_shank['brainreg_microns'] = (max(npx_shank['y'])-npx_shank['y'])
        features_npx = (max(npx_shank['y'])-np.array(features_npx))
        
        print(f'Approximation is {self.approximation_mode}')

        if harmonised:

            #Use the average distortion from the shanks that have more than one feature
            
            #get the slope from the dict
            slopes = []
            for fit in self.linear_list:
                slopes.append(self.mappings[fit]['slope'])
            slope = np.mean(slopes)

            difference = features_brainreg[0] - features_npx[0]
            npx_shank['brainreg_microns'] = difference + slope*(npx_shank['brainreg_microns'])
            self.mappings[shank]['slope'] =  slope
            self.mappings[shank]['intercept'] = float(difference)
            print(f'Slope: {slope}\n Intercept: {difference}')

        else:
            #fit the shank individually

            if len(features_brainreg) == 1:

                print('Careful! Based on inputing 1 feature, we cannot correct for expansion or shrinking of the brain \n when registering to the Allen Brain Atlas. A micron in the registered volume \n may not correspond with a real micron.')

                # Calculate the difference between the first feature point in both datasets
                difference = features_npx - features_brainreg[0]
                self.mappings[shank]['difference'] =  float(difference)
                
                # Add the difference to each y value in npx_shank to get `brainreg_microns`
                npx_shank['brainreg_microns'] = npx_shank['brainreg_microns'] - difference

            elif len(features_brainreg)> 1:

                print('Linear fit. This attempts to correct for the distortion when registering to brain atlas.')

                #convert neuropixels coordinates into brainreg coordinates
                slope, intercept = np.polyfit(features_npx, features_brainreg, 1)
                self.mappings[shank]['slope'] =  slope
                self.mappings[shank]['intercept'] =  intercept
                print(f'Slope: {slope}\n Intercept: {intercept}')

                npx_shank['brainreg_microns'] = intercept + slope*(npx_shank['brainreg_microns'])

            else: 

                print('Mode not valid')

        # Sort both DataFrames by the distance columns
        npx_shank_sorted = npx_shank.sort_values(by='brainreg_microns')
        brainreg_shank_sorted = brainreg_shank.sort_values(by='Distance from first position [um]')
        
        # Perform an asof merge to find the closest matches based on the distance
        npx_shank_merged = pd.merge_asof(
            npx_shank_sorted, 
            brainreg_shank_sorted[['Distance from first position [um]', 'allen_x', 'allen_y', 'allen_z', 'Region name']], 
            left_on='brainreg_microns', 
            right_on='Distance from first position [um]', 
            
            direction='nearest'
        )
        
        # Now npx_shank_merged contains the `allen_x` values matched from brainreg_shank
        # Output the merged DataFrame
        print(npx_shank_merged.head())

        self.save_data(npx_shank_merged, shank)

        self.merged_data[shank] = npx_shank_merged

    def determine_approximation_mode(self): 

        """
        Determines and sets the approximation mode based on the number of elements in
        'features_brainreg' for each shank.

        - If all counts >1: set to 'linear'
        - If all counts ==1: set to 'align'
        - If mixed counts and self.harmonize is True: set to 'harmonize'
        - Else: handle as needed (optional)

        Returns:
        - features_lengths (list): List containing the lengths of 'features_brainreg' for each shank.
        """
        self.features_lengths = []

        # Iterate over each shank and count 'features_brainreg' elements
        for shank in range(self.n_shanks):
            shank_key = f'shank_{shank}'

            if shank_key in self.feature_dict:
                features_brainreg = self.feature_dict[shank_key].get('features_brainreg', [])
                length = len(features_brainreg)
                self.features_lengths.append(length)
                logging.debug(f"{shank_key} - features_brainreg length: {length}")
            else:
                # If the shank key doesn't exist, append 0 and log a warning
                self.features_lengths.append(0)
                logging.warning(f"{shank_key} not found in feature_dict. Appending length 0.")

        # Determine the approximation_mode based on features_lengths
        if all(length > 1 for length in self.features_lengths):
            self.approximation_mode = 'linear'
            logging.info("All shanks have more than one feature_brainreg. Set approximation_mode to 'linear'.")
        elif all(length == 1 for length in self.features_lengths):
            self.approximation_mode = 'align'
            logging.info("All shanks have exactly one feature_brainreg. Set approximation_mode to 'align'.")
        elif any(length > 1 for length in self.features_lengths) and any(length == 1 for length in self.features_lengths):
            if self.harmonize:
                self.approximation_mode = 'harmonize'
                logging.info("Mixed features_brainreg counts and harmonize is True. Set approximation_mode to 'harmonize'.")
            else:
                self.approximation_mode = 'mixed'
                logging.info("Mixed features_brainreg counts and harmonize is False. Set approximation_mode to 'mixed'.")
        else:
            # Optional: Handle other unexpected cases
            self.approximation_mode = 'undefined'
            logging.warning("Unable to determine a valid approximation_mode. Set to 'undefined'.")

        
    def save_data(self, dataframe, shank):
        dataframe.to_csv(self.output_path / f'allen_location_shank_{shank}.csv')

    def session_table(self):

        # Ensure all shanks are merged into one large dataframe
        all_dfs = []  # List to collect dataframes
        
        # Iterate through the merged data for each shank
        for shank in range(self.n_shanks):  # Assuming there are 4 shanks: 0, 1, 2, 3
            if shank in self.merged_data:
                all_dfs.append(self.merged_data[shank])
        
        # Concatenate all dataframes into a single dataframe
        big_df = pd.concat(all_dfs, ignore_index=True)
    
        # Group by 'session' and aggregate 'Region name' into lists
        self.session_table = big_df.groupby('session')['Region name'].unique().reset_index()
        
        # Apply the cleaning function to remove any unwanted line breaks or extra spaces
        self.session_table['Region name'] = self.session_table['Region name'].apply(lambda x: [region.replace('\n', ' ').replace('  ', ' ') for region in x])

        self.session_table.to_csv(self.output_path / f'areas_per_session.csv')

        print('Saved session table')
        
    

            

